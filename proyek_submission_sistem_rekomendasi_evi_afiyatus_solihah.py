# -*- coding: utf-8 -*-
"""Proyek_Submission_Sistem_Rekomendasi_Evi_Afiyatus_Solihah_Fiks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/151PNIeU1omD1QXH89BFV9NUEyPGbgsl9

## Import Library
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import pickle
import seaborn as sns
import matplotlib
import matplotlib.pyplot as plt
matplotlib.style.use('ggplot')
# %matplotlib inline

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import Embedding
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""## Load Dataset

Load dataset merupakan proses memasukkan data dari sumber eksternal seperti file CSV ke dalam lingkungan kerja seperti Google Colab. Data biasanya dimuat ke dalam bentuk DataFrame menggunakan pustaka pandas agar bisa digunakan untuk analisis, visualisasi, atau pelatihan model machine learning. Langkah ini dilakukan di awal agar seluruh data tersedia dan siap digunakan dalam proses selanjutnya.


**Informasi Dataset**

| **Field** | **Value** |
|---------- |-----------|
| **Title** |Movie Lens Dataset           |
|**Source**| Kaggle                                                                    |
| **Maintainer**   | Hari Haran S                                                  |
| **License**      | Data files © Original Authors                                          |
| **Visibility**   | Publik                                                                    |
| **Tags**         | Earth and Nature, Arts and Entertainment, Movies and TV Shows |
| **Usability**    | 10.00
"""

# Import module yang disediakan google colab untuk kebutuhan upload file
from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download kaggle dataset and unzip the file
# !cp kaggle.json ~/.kaggle/

# !chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d aigamer/movie-lens-dataset
!unzip movie-lens-dataset.zip

links = pd.read_csv('links.csv')
links.head()

"""Pada dataset links terdapat 3 kolom. yaitu:

*   **MovieId** : ID unik untuk setiap film di dataset (digunakan internal dalam dataset).
*   **imdbId** : ID film dari situs IMDb (Internet Movie Database).
*   **tmdbId** : ID film dari situs TMDb (The Movie Database).
"""

movies = pd.read_csv('movies.csv')
movies.head()

"""Pada dataset movies terdapat 3 kolom. yaitu:

*   **MovieId** : ID unik untuk setiap film di dataset (digunakan internal dalam dataset).
*   **title** : Judul lengkap film.
*   **genres** : Daftar genre film, dipisahkan tanda |
"""

ratings = pd.read_csv('ratings.csv')
ratings.head()

"""Pada dataset ratings terdapat 4 kolom. yaitu:

*   **userId** : ID unik pengguna yang memberikan rating.
*   **MovieId** : ID film yang diberi rating.
*   **rating** : Nilai rating yang diberikan user ke film (0.5–5.0).
*   **timestamp** : Waktu saat rating diberikan
"""

tags = pd.read_csv('tags.csv')
tags.head()

"""Pada dataset tags terdapat 4 kolom. yaitu:

*   **userId** : ID pengguna yang memberi tag.
*   **MovieId** : ID film yang diberi tag.
*   **tags** : Kata kunci yang diberikan pengguna untuk film tersebut.
*   **timestamp** : Waktu saat tag diberikan.

## Exploratory Data Analysis - Deskripsi Variabel

**Eksplorasi Links Variabel**
"""

links.info()

"""Berdasarkan hasil eksekusi method df.info() untuk dataframe links, terdapat 2 kolom bertipe data numerik integer, yaitu movieId dan imdbId. Selain itu, ada 1 kolom bertipe data float64, yaitu tmdbId."""

print(links.describe())

links.shape

"""Berdasarkan hasil eksekusi method df.shape, terdapat 9742 baris dan 3 kolom

**Eksplorasi Movies Variabel**
"""

movies.info()

"""Berdasarkan hasil eksekusi method df.info() untuk dataframe movies, terdapat 1 kolom bertipe data numerik integer, yaitu movieId. Selain itu, ada 2 kolom bertipe object, yaitu title dan genres."""

print(movies.describe())

movies.shape

"""Berdasarkan hasil eksekusi method df.shape, terdapat 9742 baris dan 3 kolom"""

print('Jumlah movie:', movies.movieId.nunique())
print('Jumlah title:', movies.title.nunique())
print('Jumlah genre:', movies.genres.nunique())

print(sorted(movies['genres'].unique()))

"""**Eksplorasi Ratings Variabel**"""

ratings.info()

"""Berdasarkan hasil eksekusi method df.info() untuk dataframe ratings, terdapat 3 kolom bertipe data numerik integer, yaitu userId, movieId, dan timestamp. Selain itu, ada 1 kolom bertipe data float64, yaitu rating."""

ratings.describe()

ratings.shape

"""Berdasarkan hasil eksekusi method df.shape, terdapat 100836 baris dan 4 kolom"""

print('Jumlah Rating Unik:', ratings.rating.nunique())

print(sorted(ratings['rating'].unique()))

"""**Eksplorasi Tags Variabel**"""

tags.info()

"""Berdasarkan hasil eksekusi method df.info() untuk dataframe tags, terdapat 3 kolom bertipe data numerik integer, yaitu userId, movieId, dan timestamp. Selain itu, ada 1 kolom bertipe data float64, yaitu tag."""

print(tags.describe())

tags.shape

"""Berdasarkan hasil eksekusi method df.shape, terdapat 3683 baris dan 4 kolom"""

print('Jumlah Tag:', tags.tag.nunique())

print(sorted(tags['tag'].unique()))

"""## Exploratory Data Analysis Menangani Missing Value

Menghitung jumlah nilai yang hilang (missing values) di setiap kolom pada **DataFrame links**
"""

links.isnull().sum()

"""Menghitung Jumlah baris data yang duplikat di dalam **DataFrame links**"""

print("Duplikat di links:", links.duplicated().sum())

"""Menghitung jumlah nilai yang hilang (missing values) di setiap kolom pada **DataFrame movies**"""

movies.isnull().sum()

"""
Menghitung Jumlah baris data yang duplikat di dalam **DataFrame movies**"""

print("Duplikat di movies:", movies.duplicated().sum())

"""Menghitung jumlah nilai yang hilang (missing values) di setiap kolom pada **DataFrame ratings**"""

ratings.isnull().sum()

"""
Menghitung Jumlah baris data yang duplikat di dalam **DataFrame ratings**"""

print("Duplikat di ratings:", ratings.duplicated().sum())

"""Menghitung jumlah nilai yang hilang (missing values) di setiap kolom pada **DataFrame tags**"""

tags.isnull().sum()

"""
Menghitung Jumlah baris data yang duplikat di dalam **DataFrame tags**"""

print("Duplikat di tags:", tags.duplicated().sum())

"""## Exploratory Data Analysis Lanjutan

Jumlah rating per user dan film
"""

user_counts = ratings['userId'].value_counts()
print('Jumlah user unik yang memberikan rating:', ratings['userId'].nunique())

movie_counts = ratings['movieId'].value_counts()
print('Jumlah film unik yang diberi rating:', ratings['movieId'].nunique())

"""Menyaring user aktif (≥20 rating) untuk meningkatkan kualitas data rekomendasi."""

user_counts = ratings['userId'].value_counts()

popular_users = user_counts[user_counts >= 20].index
filtered_data = ratings[ratings['userId'].isin(popular_users)]

print("Jumlah data setelah filter:", len(filtered_data))
print("Jumlah user unik setelah filter:", filtered_data['userId'].nunique())

"""Menghitung Rata-Rata ratings"""

mean_rating = ratings['rating'].mean()
print(f'Nilai rata-rata rating film: {mean_rating:.2f}')

"""Visualisasi grafik distribusi skor rating"""

plt.figure(figsize=(8, 4))
sns.histplot(data=ratings, x='rating', bins=10, kde=True, color='blue')
plt.title('Sebaran Skor Rating Film')
plt.xlabel('Skor Rating')
plt.ylabel('Jumlah Film')
plt.tight_layout()
plt.show()

"""Secara keseluruhan, gambar grafik diatas menggambarkan bahwa penonton cenderung memberikan rating yang positif atau cukup positif terhadap film. Mayoritas film mendapatkan rating 3, 4, atau 5 bintang, dengan 4 bintang menjadi rating yang paling sering diberikan. Ini bisa berarti bahwa rata-rata film yang tersedia memiliki kualitas yang dianggap "baik" oleh sebagian besar penonton, atau bahwa penonton cenderung memberikan rating yang lebih tinggi.

Menampilkan 20 Film Teratas Berdasarkan Jumlah Rating
"""

# Hitung jumlah rating per film dan gabungkan dengan judul film
rating_per_film = ratings['movieId'].value_counts()
rating_per_film = pd.merge(rating_per_film, movies[['movieId', 'title']], left_index=True, right_on='movieId')
rating_per_film = rating_per_film.rename(columns={'movieId_x': 'movieId', 'count': 'total_rating'})

# Urutkan film berdasarkan jumlah rating terbanyak
top_rated_films = rating_per_film.sort_values(by='total_rating', ascending=False)

print("20 Film Teratas Berdasarkan Jumlah Rating:\n ")
print(top_rated_films.head(20))

"""Visualisasi 20 film dengan jumlah rating terbanyak"""

plt.figure(figsize=(12, 6))
sns.barplot(data=top_rated_films.head(20), x='total_rating', y='title', hue='title', palette='Blues', legend=False)
plt.title('20 Film dengan Jumlah Rating Terbanyak')
plt.xlabel('Total Rating')
plt.ylabel('Judul')
plt.tight_layout()
plt.show()

"""Secara keseluruhan, grafik ini menggambarkan film-film yang paling sering diulas atau diberi rating oleh pengguna, menyoroti popularitas dan daya tarik abadi dari sejumlah film klasik, terutama dari era 1990-an. Data ini menunjukkan bahwa film-film klasik dari era tersebut sangat populer di kalangan pemberi rating, dan penonton secara umum cenderung memberikan ulasan yang positif atau sangat baik terhadap film-film yang mereka tonton. Dalam dataset ini, film-film populer yang paling banyak mendapatkan rating, seperti "Forrest Gump," "Shawshank Redemption," dan "Pulp Fiction," didominasi oleh rilis tahun 1990-an, terutama dari tahun 1994, yang menunjukkan daya tarik abadi dari karya-karya klasik tersebut. Meskipun mencakup berbagai genre, daftar film dengan rating terbanyak ini secara tidak langsung merefleksikan popularitas tinggi di kalangan penonton aktif yang memberikan rating, dengan rentang jumlah rating antara 200 hingga lebih dari 300.

Menampilkan 20 Pengguna Teraktif dalam Memberikan Rating
"""

ratings_per_user = ratings['userId'].value_counts()
most_active_users = ratings_per_user.sort_values(ascending=False)

print("20 Pengguna Teraktif dalam Memberikan Rating:")
print(most_active_users.head(20))

"""Visualisasi 20 pengguna teraktif"""

plt.figure(figsize=(12, 6))
sns.barplot(
    x=most_active_users.head(20).values,
    y=most_active_users.head(20).index.astype(str),
    hue=most_active_users.head(20).index.astype(str),
    palette='Blues',
    legend=False
)
plt.title('20 Pengguna Teraktif Berdasarkan Jumlah Rating')
plt.xlabel('Total Rating yang Diberikan')
plt.ylabel('ID Pengguna')
plt.tight_layout()
plt.show()

"""Secara keseluruhan, grafik ini mengungkapkan bahwa platform rating film ini memiliki sejumlah kecil pengguna yang sangat aktif dan berdedikasi yang berkontribusi secara signifikan terhadap volume data rating. Kondisi ini berimplikasi pada potensi bias dalam statistik keseluruhan, karena preferensi atau karakteristik rating dari kelompok inti pengguna ini dapat secara signifikan memengaruhi tren yang diamati. Oleh karena itu, saat menganalisis data dari platform ini, sangat krusial untuk memahami bahwa meskipun volume rating tinggi, distribusinya tidak merata dan sangat bergantung pada kontribusi berharga dari segelintir pengguna inti tersebut.

Visualisasi 20 genre film yang paling sering muncul
"""

# Ubah kolom 'genres' menjadi format satu genre per baris
genre_per_row = movies['genres'].str.split('|').explode()
genre_frequencies = genre_per_row.value_counts()

top_genres = genre_frequencies.sort_values(ascending=False).head(20)

plt.figure(figsize=(10, 8))
sns.barplot(y=top_genres.index, x=top_genres.values, palette='Blues_r')

plt.title('Sebaran 20 Genre Film Terbanyak')
plt.xlabel('Jumlah Film')
plt.ylabel('Genre')
plt.tight_layout()
plt.show()

"""Secara keseluruhan, grafik ini dengan jelas menunjukkan bahwa genre Drama dan Comedy adalah pilar utama dalam kumpulan data film ini, diikuti oleh genre populer lainnya seperti Thriller dan Action, sementara banyak genre lain memiliki representasi yang jauh lebih kecil. Dalam dataset film ini, genre Drama dan Comedy mendominasi dengan jumlah film masing-masing melebihi dan mendekati 4000, menunjukkan produktivitas atau popularitas yang signifikan. Genre seperti Thriller dan Action juga memiliki representasi kuat dengan sekitar 1800-2000 film. Namun, terdapat rentang popularitas yang luas, di mana genre minoritas seperti Film-Noir, IMAX, Western, dan Musical memiliki jumlah film yang jauh lebih sedikit, hanya beberapa ratus atau kurang. Perbedaan ini menyoroti fokus industri pada genre tertentu, yang penting untuk dipertimbangkan dalam sistem rekomendasi guna memastikan variasi dan relevansi genre minoritas bagi pengguna.

## Data Preparation

Menggabungkan Dataset yang digunakan (ratings dan movies)
"""

movies_ratings = pd.merge(ratings, movies, on='movieId')

movies_ratings.shape

print('Jumlah seluruh data: ', len(movies_ratings))

movies_ratings.head()

"""Mengecek duplikat data dari data yang telah digabungkan"""

dupes = movies_ratings.duplicated()

print("Jumlah baris duplikat:", dupes.sum())
print(movies_ratings[dupes].head())

"""Cek missing value dengan fungsi isnull()"""

movies_ratings.isnull().sum()

final = movies_ratings[['userId', 'movieId', 'title', 'genres', 'rating']]
final.head()

final.shape

final.info()

# Mengecek missing values
final.isnull().sum()

#Mengecek apakah ada data duplikat
print('Jumlah data duplikat:', final.duplicated().sum())

duplikat = final[final.duplicated()]
print(duplikat)

"""## Model Development Content Based Filtering"""

data = final.copy()
data.sample(5)

"""**TF-IDF Vectorization**

Filter metadata film sebanyak sampel 5000 rating.
"""

sampled_data = data.sample(n=5000, random_state=42).reset_index(drop=True)
sampled_movie_ids = sampled_data['movieId'].unique()
filtered_movies = movies[movies['movieId'].isin(sampled_movie_ids)].reset_index(drop=True)

"""Menghapus label kosong dan mengganti pemisah genre '|' dengan spasi di kolom genres."""

movies['genres'] = movies['genres'].replace('(no genres listed)', '', regex=False).str.replace('|', ' ', regex=False)

"""Mengubah daftar genre film menjadi representasi numerik TF-IDF"""

tfv = TfidfVectorizer()
tfv.fit(movies['genres'])

tfv.get_feature_names_out()

"""Menghitung dan menyimpan matriks TF-IDF dari genre film"""

tfidf_matrix = tfv.fit_transform(movies['genres'])

tfidf_matrix.shape

"""Buat DataFrame TF-IDF genre per film dan tampilkan sampel."""

tfidf_dense = tfidf_matrix.todense()

tfidf_df = pd.DataFrame(
    tfidf_dense,
    columns=tfv.get_feature_names_out(),
    index=movies['title']
)

tfidf_df.sample(20, axis=0).sample(10, axis=1)

"""**Cosine Similarity**

Membuat dan menampilkan matriks kemiripan film berdasarkan genre menggunakan cosine similarity.
"""

cosine_sim = cosine_similarity(tfidf_matrix)

df_cosine_sim = pd.DataFrame(cosine_sim, index=movies['title'], columns=movies['title'])
print('Shape:', df_cosine_sim.shape)

df_cosine_sim.sample(10, axis=1).sample(20, axis=0)

"""Mendapatkan Rekomendasi"""

def movie_recommendations(judul_film, similarity_data=df_cosine_sim, items=movies[['title', 'genres']], k=10):
    """
    Rekomendasi Film berdasarkan kemiripan DataFrame

    Parameter:
    ---
    judul_film : str
        Judul film (harus ada sebagai index/kolom di similarity_data)
    similarity_data : pd.DataFrame
        Matriks kemiripan (similarity matrix) simetris dengan judul film sebagai index dan kolom
    items : pd.DataFrame
        DataFrame yang memuat informasi film, minimal kolom 'title' dan fitur lain (misal genre)
    k : int, default=5
        Jumlah film rekomendasi yang ingin ditampilkan

    ---
    Fungsi ini mengembalikan DataFrame berisi k film yang paling mirip dengan judul_film
    berdasarkan matriks kemiripan similarity_data, disertai metadata film dari items.
    """

    index = similarity_data.loc[:, judul_film].to_numpy().argpartition(range(-1, -k-1, -1))

    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(judul_film, errors='ignore')

    closest_df = pd.DataFrame(closest, columns=['title'])

    return closest_df.merge(items, on='title').head(k)

""" Melihat detail film yang akan direkomendasikan"""

movies[movies['title'].str.contains('Mad Max (1979)', case=False, regex=False)]

"""Memanggil fungsi untuk memberikan rekomendasi film mirip dengan "Mad Max (1979)"
"""

movie_recommendations('Mad Max (1979)')

movie_recommendations('Against All Odds (1984)')

movie_recommendations('Last Train Home (2009)')

"""Evaluasi Precision@k untuk Cosine Similarity"""

def precision_at_k(recommended_movies, relevant_movies, k):
    """
    Menghitung Precision@k.

    Args:
      recommended_movies: List film yang direkomendasikan.
      relevant_movies: List film relevan (ground truth).
      k: Jumlah film teratas yang dipertimbangkan.

    Returns:
      float: Nilai Precision@k.
    """
    if k == 0 or not recommended_movies:
        return 0.0

    recommended_at_k = recommended_movies[:k]
    relevant_found = [movie for movie in recommended_at_k if movie in relevant_movies]

    return len(relevant_found) / k


# Simulasi Data Hasil Rekomendasi (Cosine Similarity)
recommendations_cosine = {
    'Mad Max (1979)': movie_recommendations('Mad Max (1979)')['title'].tolist(),
    'Against All Odds (1984)': movie_recommendations('Against All Odds (1984)')['title'].tolist(),
    'Last Train Home (2009)': movie_recommendations('Last Train Home (2009)')['title'].tolist(),
}

# Contoh data ground truth (film yang sebenarnya relevan)
ground_truth = {
    'Mad Max (1979)': [
        'Lost in Space (1998)',
        'Waterworld (1995)',
        'Time Machine, The (2002)',
        "Logan's Run (1976)",
        'Transformers: Age of Extinction (2014)',
        'Power/Rangers (2015)',
        'Spacehunter: Adventures in the Forbidden Zone (1983)',
        'Tron (1982)',
        "Assassin's Creed (2016)",
        'Iron Man (2008)'
    ],
    'Against All Odds (1984)': [
        'Temptress Moon (Feng Yue) (1996)',
        'Meet Joe Black (1998)',
        'Kama Sutra: A Tale of Love (1996)',
        'Love Jones (1997)',
        'Anything for Love (2016)',
        "Paris, I Love You (Paris, je t'aime) (2006)",
        'Message in a Bottle (1999)',
        "'Tis the Season for Love (2015)",
        'Jack and Sarah (1995)',
        'Open Hearts (Elsker dig for evigt) (2002)'
    ],
    'Last Train Home (2009)': [
        'Seve (2014)',
        'Rude Boy (1980)',
        'Sicko (2007)',
        'Blood of the Beasts (Sang des bêtes, Le) (1949)',
        'Story of the Weeping Camel, The (Geschichte vom weinenden Kamel) (2003)',
        'Titicut Follies (1967)',
        'Looking for Richard (1996)',
        'On the Ropes (1999)',
        'Pirates of Silicon Valley (1999)',
        'Oceans (Océans) (2009)'
    ]
}

def evaluate_precision_for_all_movies(recommendation_data, ground_truth_data, k_values):
    """
    Mengevaluasi Precision@k rata-rata untuk banyak film input.

    Args:
      recommendation_data (dict): Dictionary {judul_film: list rekomendasi film}.
      ground_truth_data (dict): Dictionary {judul_film: list film relevan}.
      k_values (list): List nilai k yang ingin dievaluasi.

    Returns:
      pd.DataFrame: DataFrame berisi rata-rata Precision@k untuk setiap nilai k.
    """
    results = {}
    for k in k_values:
        total_precision = 0
        evaluated_movies_count = 0

        for movie_title, recommended_list in recommendation_data.items():
            if movie_title in ground_truth_data:
                relevant_list = ground_truth_data[movie_title]
                if relevant_list:
                    precision_val = precision_at_k(recommended_list, relevant_list, k)
                    total_precision += precision_val
                    evaluated_movies_count += 1
            else:
                print(f"Peringatan: Tidak ada ground truth untuk film '{movie_title}'. Dilewati.")

        average_precision = total_precision / evaluated_movies_count if evaluated_movies_count > 0 else 0
        results[f'Precision@{k}'] = average_precision

    return pd.DataFrame([results])

# Nilai k yang ingin dievaluasi
k_to_evaluate = [1, 3, 5, 10]

# Menampilkan hasil evaluasi Precision@k
print("Evaluasi Precision@k untuk Cosine Similarity\n")
cosine_precision_results = evaluate_precision_for_all_movies(
    recommendations_cosine,
    ground_truth,
    k_to_evaluate
)

print(cosine_precision_results)

"""## Model Development dengan Collaborative Filtering"""

df_ratings = ratings
df_ratings

"""**Data Preparation Model Development dengan Collaborative Filtering**

Membuat encoding userID ke angka dan sebaliknya
"""

user_ids = df_ratings['userId'].unique().tolist()
print('list userId: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userId : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userId: ', user_encoded_to_user)

"""Membuat encoding movieId ke angka dan sebaliknya"""

movie_ids = df_ratings['movieId'].unique().tolist()

# Melakukan proses encoding placeID
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke placeID
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}
print('encoded angka ke movieId: ', movie_encoded_to_movie)

"""Mengubah userId dan movieId ke format encoded di dataframe."""

df_ratings['user'] = df_ratings['userId'].map(user_to_user_encoded)
df_ratings['movie'] = df_ratings['movieId'].map(movie_to_movie_encoded)

"""Menghitung user, film, dan menampilkan info rating"""

num_users = len(user_to_user_encoded)
num_movie = len(movie_to_movie_encoded)

df_ratings['rating'] = df_ratings['rating'].values.astype(np.float32)

min_rating = min(df_ratings['rating'])
max_rating = max(df_ratings['rating'])

print('Number of User: {}, Number of Movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""Mengacak urutan data df_ratings"""

df = df_ratings.sample(frac=1, random_state=42)
df

"""Mempersiapkan data input (user, movie) dan target rating yang sudah dinormalisasi, lalu membagi jadi data train dan validasi."""

x = df[['user', 'movie']].values
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""Membangun Model Colaborative Filtering"""

num_users = df['userId'].nunique()
num_movies = df['movieId'].nunique()

class RecommenderNet(tf.keras.Model):
    def __init__(self, num_users, num_movies, embedding_size=50, output_activation='sigmoid', **kwargs):
        super(RecommenderNet, self).__init__(**kwargs)
        self.output_activation = output_activation

        self.user_embedding = layers.Embedding(
            num_users, embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1)

        self.movie_embedding = layers.Embedding(
            num_movies, embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.movie_bias = layers.Embedding(num_movies, 1)

        self.dot = layers.Dot(axes=1)
        self.dropout = layers.Dropout(0.3)

    def call(self, inputs):
        user_vec = self.dropout(self.user_embedding(inputs[:, 0]))
        user_bias = self.user_bias(inputs[:, 0])

        movie_vec = self.dropout(self.movie_embedding(inputs[:, 1]))
        movie_bias = self.movie_bias(inputs[:, 1])

        x = self.dot([user_vec, movie_vec]) + user_bias + movie_bias

        return tf.nn.sigmoid(x) if self.output_activation == 'sigmoid' else x

"""Membuat callback untuk menghentikan pelatihan jika validasi loss tidak membaik selama 3 epoch.








"""

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=3,             # Hentikan jika 3 epoch berturut-turut val_loss tidak membaik
    restore_best_weights=True,  # Kembalikan bobot ke yang terbaik (bukan terakhir)
    verbose=1
)

"""Membuat dan menyiapkan model rekomendasi untuk pelatihan."""

model = RecommenderNet(num_users, num_movies, embedding_size=50)

model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.0001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Melatih model dengan data training dan validasi."""

history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=64,
    epochs=100,
    verbose=1,
    validation_data=(x_val, y_val),  # pastikan kamu split validation set
    callbacks=[early_stopping]
)

"""Visualisasi RMSE training dan validation tiap epoch."""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.grid(True)
plt.show()

"""Membuat input (user, film belum ditonton) untuk prediksi rekomendasi."""

movie_df = movies
ratings_df = ratings

# Ambil satu userId secara acak dari data rating
user_id = ratings_df.userId.sample(1).iloc[0]

# Ambil semua film yang sudah ditonton oleh user tersebut (dari data rating)
movies_watched_by_user = ratings_df[ratings_df.userId == user_id]

# Ambil semua movieId dari daftar film yang belum ditonton oleh user
movies_not_watched = movie_df[~movie_df['movieId'].isin(movies_watched_by_user.movieId.values)]['movieId']

# Filter ulang agar hanya menyertakan film yang ada dalam movie_to_movie_encoded
movies_not_watched = list(set(movies_not_watched).intersection(set(movie_to_movie_encoded.keys())))

# Encode movieId (ubah movieId asli jadi indeks encoding), lalu jadikan bentuk array dua dimensi [[movie_id]]
movies_not_watched = [[movie_to_movie_encoded.get(x)] for x in movies_not_watched]

# Ambil userId hasil encoding (sudah dilatih sebelumnya)
user_encoder = user_to_user_encoded.get(user_id)

# Gabungkan user encoded ID dengan daftar film yang belum ditonton
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)
)

"""Memprediksi dan menampilkan 10 rekomendasi film terbaik untuk user berdasarkan model serta 5 film favorit user dari data asli."""

ratings = model.predict(user_movie_array).flatten()

# Ambil indeks 10 prediksi tertinggi (argsort() dari kecil ke besar → dibalik)
top_ratings_indices = ratings.argsort()[-10:][::-1]

# Ambil movieId asli dari indeks film hasil prediksi
recommended_movie_ids = [
    movie_encoded_to_movie.get(movies_not_watched[x][0]) for x in top_ratings_indices
]

# Tampilkan userId yang sedang diproses dalam format misal: U0015
print(f"Showing recommendations for users: U{user_id:04d}")
print("=" * 30)

# Film dengan rating tertinggi dari user tersebut
print("\nFilm with high ratings from user")
print("-" * 30)

# Ambil 5 film tertinggi yang pernah di-rating user ini
top_movies = (
    movies_watched_by_user.sort_values(by='rating', ascending=False)
    .head(5)
    .movieId.values
)

# Tampilkan judul dari 5 film tertinggi tersebut
for m in movie_df[movie_df.movieId.isin(top_movies)].itertuples():
    print(f"{m.title}")

print("\nTop 10 movie recommendation")
print("-" * 30)

for m in movie_df[movie_df.movieId.isin(recommended_movie_ids)].itertuples():
    print(f"{m.title}")